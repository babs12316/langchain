Langchain concepts
# ğŸ§  LangChain GitHub Retriever Demo

This project demonstrates how to **build a simple Retrieval-Augmented Generation (RAG)** system using a GitHub repository as the source of documents.  
The main goal is to fetch content from `README.md` files in the repo, embed it, store it in a vector store, and retrieve relevant context for user queries.

## ğŸš€ Tech Stack

- ğŸ **Python 3.9+**
- ğŸ§° **LangChain** â€“ framework for building applications with LLMs
- ğŸª„ **Hugging Face Sentence Transformers** â€“ for generating vector embeddings  
- ğŸ’¾ **InMemoryVectorStore** â€“ lightweight and fast vector store for local development
- ğŸ“‚ **GitHub File Loader** â€“ loads files directly from a public or private GitHub repository
- âœ‚ï¸ **Recursive Character Text Splitter** â€“ splits text into manageable chunks

## ğŸ§  How It Works

1. The loader fetches Markdown files from the GitHub repository (e.g., this `README.md`).
2. The text is split into overlapping chunks to preserve context.
3. Embeddings are generated using `sentence-transformers/all-mpnet-base-v2`.
4. The chunks and their embeddings are stored in the in-memory vector store.
5. A retriever is used to fetch the most relevant chunks based on user queries.
6. The LLM can then use this retrieved content to answer the question.

## ğŸ§ª Example Query

You can ask:

```text
"What programming language is used in this repository?"
